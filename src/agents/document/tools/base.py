"""Shared utilities and input schemas for document tools.

This module contains common functions, formatters, and Pydantic schemas
used across multiple document processing tools.
"""

import hashlib
import json
import logging
import time
from pathlib import Path
from typing import Optional, List

from pydantic import BaseModel, Field

from src.utils.async_utils import run_async
from src.utils.gcs_utils import is_gcs_path, parse_gcs_uri

logger = logging.getLogger(__name__)


# =============================================================================
# Path Derivation Utilities
# =============================================================================

def derive_org_and_folder(parsed_file_path: str) -> tuple:
    """
    Extract org_name and folder_name from parsed_file_path.

    Handles both relative paths and full GCS URIs:
    - Relative: "Acme corp/parsed/invoices/Sample1.md" -> ("Acme corp", "invoices")
    - GCS URI: "gs://bucket/Acme corp/parsed/invoices/Sample1.md" -> ("Acme corp", "invoices")
    """
    if not parsed_file_path or 'parsed' not in parsed_file_path:
        return "", ""

    # Normalize: strip GCS prefix if present (gs://bucket/path -> path)
    path = parsed_file_path
    if is_gcs_path(path):
        _, path = parse_gcs_uri(path)  # Extract blob path (org/parsed/folder/doc.md)

    parts = path.split('/')
    try:
        parsed_idx = parts.index('parsed')
        org_name = '/'.join(parts[:parsed_idx])
        folder_parts = parts[parsed_idx + 1:-1]  # Everything between 'parsed' and filename
        folder_name = '/'.join(folder_parts) if folder_parts else ""
        return org_name, folder_name
    except ValueError:
        return "", ""


def derive_document_base(document_name: str) -> str:
    """
    Get document name without extension.

    Example: "Sample1.md" -> "Sample1"
    """
    return Path(document_name).stem


def build_content_path(parsed_file_path: str, content_type: str, document_name: str) -> str:
    """
    Build GCS path for a content type (summary, faq, questions).

    NOTE: This function is a FALLBACK. Frontend should provide explicit paths.

    Args:
        parsed_file_path: e.g., "Acme corp/parsed/invoices/Sample1.md"
        content_type: 'summary', 'faq', or 'questions'
        document_name: e.g., "Sample1.md"

    Returns:
        GCS path, e.g., "Acme corp/summary/invoices/Sample1.md" or
        "Acme corp/faq/invoices/Sample1.json"
    """
    org_name, folder_name = derive_org_and_folder(parsed_file_path)
    doc_base = derive_document_base(document_name)
    extension = ".md" if content_type == "summary" else ".json"
    filename = f"{doc_base}{extension}"

    # Build path parts, filtering out empty strings
    parts = [p for p in [org_name, content_type, folder_name, filename] if p]
    return '/'.join(parts)


# =============================================================================
# Content Formatting Functions
# =============================================================================

def format_summary_markdown(
    summary: str,
    document_name: str,
    model: str,
    generated_at: str,
    content_hash: Optional[str] = None
) -> str:
    """Format summary as markdown with metadata footer."""
    footer_lines = [f"_Generated by {model} on {generated_at}_"]
    if content_hash:
        footer_lines.append(f"_Content hash: {content_hash[:16]}..._")

    footer = '\n'.join(footer_lines)
    return f"# Summary\n\n{summary}\n\n---\n{footer}\n"


def format_faqs_json(
    faqs: list,
    document_name: str,
    parsed_file_path: str,
    model: str,
    generated_at: str,
    content_hash: Optional[str] = None
) -> str:
    """Format FAQs as JSON with metadata."""
    data = {
        "metadata": {
            "document_name": document_name,
            "parsed_file_path": parsed_file_path,
            "generated_at": generated_at,
            "model": model,
        },
        "faqs": faqs
    }
    if content_hash:
        data["metadata"]["content_hash"] = content_hash

    return json.dumps(data, indent=2, ensure_ascii=False)


def format_questions_json(
    questions: list,
    document_name: str,
    parsed_file_path: str,
    model: str,
    generated_at: str,
    content_hash: Optional[str] = None
) -> str:
    """Format questions as JSON with metadata."""
    data = {
        "metadata": {
            "document_name": document_name,
            "parsed_file_path": parsed_file_path,
            "generated_at": generated_at,
            "model": model,
        },
        "questions": questions
    }
    if content_hash:
        data["metadata"]["content_hash"] = content_hash

    return json.dumps(data, indent=2, ensure_ascii=False)


# =============================================================================
# LLM Response Parsing
# =============================================================================

def extract_llm_text(content) -> str:
    """
    Safely extract text from LLM response content.

    Handles cases where content may be:
    - A string (normal case)
    - A list of content blocks (Gemini multi-part response)
    - An object with a 'text' attribute
    """
    if isinstance(content, str):
        return content.strip()
    elif isinstance(content, list):
        # Join text from all content blocks
        texts = []
        for item in content:
            if isinstance(item, str):
                texts.append(item)
            elif hasattr(item, 'text'):
                texts.append(item.text)
            elif isinstance(item, dict) and 'text' in item:
                texts.append(item['text'])
        return '\n'.join(texts).strip()
    elif hasattr(content, 'text'):
        return content.text.strip()
    else:
        return str(content).strip()


def compute_content_hash(content: str) -> str:
    """Compute SHA-256 hash of content for cache validation."""
    return hashlib.sha256(content.encode()).hexdigest()


# =============================================================================
# Tool Input Schemas
# =============================================================================

class DocumentLoaderInput(BaseModel):
    """Input for document loader tool."""
    document_name: str = Field(description="Name of the document to load (e.g., 'Sample1.md')")
    parsed_file_path: str = Field(description="GCS path to parsed document (e.g., 'Acme corp/parsed/invoices/Sample1.md')")


class SummaryGeneratorInput(BaseModel):
    """Input for summary generator tool."""
    content: str = Field(description="Document content to summarize")
    document_name: str = Field(description="Name of the source document for caching")
    max_words: int = Field(default=500, description="Maximum words for summary")
    organization_id: Optional[str] = Field(default=None, description="Organization ID for multi-tenant isolation")


class FAQGeneratorInput(BaseModel):
    """Input for FAQ generator tool."""
    content: str = Field(description="Document content to generate FAQs from")
    document_name: str = Field(description="Name of the source document for caching")
    num_faqs: int = Field(default=5, description="Number of FAQs to generate")
    organization_id: Optional[str] = Field(default=None, description="Organization ID for multi-tenant isolation")


class QuestionGeneratorInput(BaseModel):
    """Input for question generator tool."""
    content: str = Field(description="Document content to generate questions from")
    document_name: str = Field(description="Name of the source document for caching")
    num_questions: int = Field(default=10, description="Number of questions to generate")
    organization_id: Optional[str] = Field(default=None, description="Organization ID for multi-tenant isolation")


class ContentPersistInput(BaseModel):
    """Input for content persist tool."""
    document_name: str = Field(description="Name of the source document")
    parsed_file_path: str = Field(description="GCS path to parsed document (e.g., 'Acme corp/parsed/invoices/Sample1.md')")
    summary: Optional[str] = Field(default=None, description="Generated summary")
    faqs: Optional[str] = Field(default=None, description="Generated FAQs as JSON string")
    questions: Optional[str] = Field(default=None, description="Generated questions as JSON string")
    content_hash: Optional[str] = Field(default=None, description="SHA-256 hash of source document content for cache invalidation")
    organization_id: Optional[str] = Field(default=None, description="Organization ID for multi-tenant isolation")


class RAGSearchInput(BaseModel):
    """Input for RAG search tool."""
    query: str = Field(description="User's search query")
    organization_name: str = Field(description="Organization name for store lookup")
    folder_filter: Optional[str] = Field(default=None, description="Folder name to filter search results")
    file_filter: Optional[str] = Field(default=None, description="File name to filter search results")
    search_mode: str = Field(default="hybrid", description="Search mode: semantic, keyword, or hybrid")
    max_sources: int = Field(default=5, ge=1, le=20, description="Maximum number of citations to return")
